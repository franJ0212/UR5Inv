{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pj9iLNhMauen"
      },
      "outputs": [],
      "source": [
        "path_consultoria = '/content/drive/MyDrive/Consultoria/Final'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfY217uPay5l",
        "outputId": "6461920a-0d25-4b35-90ff-069e17bca94a"
      },
      "outputs": [],
      "source": [
        "!cp -r {path_consultoria}/UR5Inv /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjLKWLuybIju",
        "outputId": "bfe4fbff-2c47-4440-8373-e0653da22318"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9iotU2vRrES"
      },
      "outputs": [],
      "source": [
        "from UR5Inv.LTSM import LSTMInversaUR5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OPMALOcdtzk"
      },
      "outputs": [],
      "source": [
        "def comparar_modelos_lstm(nombre_modelo, ruta_datos, modelo, ruta_csv=None):\n",
        "    \"\"\"\n",
        "    Crea o actualiza un archivo CSV con métricas de comparación para modelos LSTM.\n",
        "    Aprovecha las métricas ya calculadas por el modelo sin recalcularlas.\n",
        "\n",
        "    Parámetros:\n",
        "        nombre_modelo (str): Nombre identificador del modelo (ej: \"Trayectorias_LSTM\").\n",
        "        ruta_datos (str): Ruta al archivo de datos utilizado para entrenar el modelo.\n",
        "        modelo (LSTMInversaUR5 o LSTMInversaUR5Simple): Instancia del modelo LSTM entrenado.\n",
        "        ruta_csv (str, opcional): Ruta donde guardar el archivo CSV.\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import os\n",
        "    import time\n",
        "    import torch\n",
        "\n",
        "    # Determinar ruta del CSV si no se especifica\n",
        "    if ruta_csv is None:\n",
        "        directorio_datos = os.path.dirname(ruta_datos)\n",
        "        ruta_csv = os.path.join(directorio_datos, \"comparacion_modelos.csv\")\n",
        "\n",
        "    # Obtener resultados de la evaluación del modelo (sin recalcular)\n",
        "    # Asumimos que el modelo ya ha sido evaluado\n",
        "    results = modelo.evaluar_total() if hasattr(modelo, 'evaluar_total') else None\n",
        "\n",
        "    # Determinar seq_len según el tipo de modelo\n",
        "    if hasattr(modelo, 'seq_len'):\n",
        "        # Para modelos simples\n",
        "        seq_len = modelo.seq_len\n",
        "    elif hasattr(modelo, 'study') and modelo.study is not None:\n",
        "        # Para modelos optimizados con Optuna\n",
        "        seq_len = modelo.study.best_params.get('seq_len', 20)\n",
        "    else:\n",
        "        # Valor por defecto si no se encuentra\n",
        "        seq_len = 20\n",
        "        print(\"Advertencia: No se pudo determinar seq_len, usando valor por defecto (20)\")\n",
        "\n",
        "    # Calcular tiempo de inferencia promedio (1000 muestras)\n",
        "    tiempos = []\n",
        "    n_muestras = min(1000, len(modelo.X) - seq_len)\n",
        "    indices = np.random.choice(n_muestras, min(n_muestras, 500), replace=False)\n",
        "\n",
        "    for idx in indices:\n",
        "        # Obtener una secuencia para predecir\n",
        "        x_seq = modelo.X[idx:idx+seq_len]\n",
        "\n",
        "        inicio = time.time()\n",
        "        # Usar el método correcto según el tipo de modelo\n",
        "        if hasattr(modelo, 'predecir'):\n",
        "            modelo.predecir(x_seq)\n",
        "        else:\n",
        "            modelo._predict_numpy(x_seq)\n",
        "        fin = time.time()\n",
        "        tiempos.append(fin - inicio)\n",
        "\n",
        "    tiempo_inf = np.mean(tiempos) * 1000  # ms\n",
        "\n",
        "    # Calcular tamaño aproximado del modelo\n",
        "    if hasattr(modelo, 'modelo_final') and modelo.modelo_final is not None:\n",
        "        # Contar parámetros del modelo optimizado\n",
        "        parametros = sum(p.numel() for p in modelo.modelo_final.parameters())\n",
        "    elif hasattr(modelo, 'model') and modelo.model is not None:\n",
        "        # Contar parámetros del modelo simple\n",
        "        parametros = sum(p.numel() for p in modelo.model.parameters())\n",
        "    else:\n",
        "        # Estimación si no se puede calcular directamente\n",
        "        hidden_size = 128  # Valor por defecto\n",
        "        if hasattr(modelo, 'hidden_size'):\n",
        "            hidden_size = modelo.hidden_size\n",
        "        elif hasattr(modelo, 'study') and modelo.study is not None:\n",
        "            hidden_size = modelo.study.best_params.get('hidden_size', 128)\n",
        "\n",
        "        num_layers = 2  # Valor por defecto\n",
        "        if hasattr(modelo, 'num_layers'):\n",
        "            num_layers = modelo.num_layers\n",
        "        elif hasattr(modelo, 'study') and modelo.study is not None:\n",
        "            num_layers = modelo.study.best_params.get('num_layers', 2)\n",
        "\n",
        "        # Estimación muy básica del número de parámetros\n",
        "        parametros = (modelo.input_dim * hidden_size * 4 + hidden_size * hidden_size * 4 * (num_layers - 1) +\n",
        "                     hidden_size * modelo.output_dim + hidden_size + modelo.output_dim)\n",
        "\n",
        "    # Crear diccionario con las métricas de los resultados existentes\n",
        "    if results:\n",
        "        metricas = {\n",
        "            'modelo': nombre_modelo,\n",
        "            'MSE_train': results['train']['mse_rad'] if results['train'] else None,\n",
        "            'MSE_test': results['test']['mse_rad'] if results['test'] else None,\n",
        "            'MSE_global': results['total']['mse_rad'],\n",
        "            'tamaño_modelo': parametros,\n",
        "            'tiempo_inf': tiempo_inf\n",
        "        }\n",
        "\n",
        "        # Añadir errores L1 por articulación\n",
        "        if 'error_por_artic' in results:\n",
        "            error_por_artic = results['error_por_artic']\n",
        "            for i, error in enumerate(error_por_artic):\n",
        "                metricas[f'Errorq{i}L1'] = np.sqrt(error)  # Convertir MSE a error L1 aprox.\n",
        "    else:\n",
        "        # Si no tenemos resultados, crear métricas básicas\n",
        "        metricas = {\n",
        "            'modelo': nombre_modelo,\n",
        "            'MSE_train': np.mean(modelo.train_losses[-1]) if hasattr(modelo, 'train_losses') and len(modelo.train_losses) > 0 else None,\n",
        "            'MSE_test': np.mean(modelo.val_losses[-1]) if hasattr(modelo, 'val_losses') and len(modelo.val_losses) > 0 else None,\n",
        "            'MSE_global': np.mean(modelo.train_losses[-1]) if hasattr(modelo, 'train_losses') and len(modelo.train_losses) > 0 else None,\n",
        "            'tamaño_modelo': parametros,\n",
        "            'tiempo_inf': tiempo_inf\n",
        "        }\n",
        "\n",
        "    # Crear o actualizar el archivo CSV\n",
        "    try:\n",
        "        df_existente = pd.read_csv(ruta_csv)\n",
        "        if nombre_modelo in df_existente['modelo'].values:\n",
        "            df_existente = df_existente[df_existente['modelo'] != nombre_modelo]\n",
        "        df_nueva_fila = pd.DataFrame([metricas])\n",
        "        df_final = pd.concat([df_existente, df_nueva_fila], ignore_index=True)\n",
        "    except (FileNotFoundError, pd.errors.EmptyDataError):\n",
        "        df_final = pd.DataFrame([metricas])\n",
        "\n",
        "    df_final.to_csv(ruta_csv, index=False)\n",
        "    print(f\"Comparación actualizada en: {ruta_csv}\")\n",
        "\n",
        "    return df_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTrt4SD0tMu3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import optuna\n",
        "import shutil\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sQb_cOnZaqW"
      },
      "source": [
        "## Datos comandos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjbxiZxSLdNK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dMFkw6No4FL"
      },
      "outputs": [],
      "source": [
        "!cp -r \"Comandos_LSTM\" /content/drive/MyDrive/Consultoria/Final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X_9EtK-zhM8C",
        "outputId": "819f4ff3-85f6-404f-f1ff-4e172eb7d160"
      },
      "outputs": [],
      "source": [
        "\n",
        "datos = r\"/content/drive/MyDrive/Consultoria/Final/Data/2dos/datos_comandos.csv\"\n",
        "\n",
        "modelo = LSTMInversaUR5(\n",
        "    ruta_datos=datos,\n",
        "    test_size=0.25,\n",
        "    random_state=42,\n",
        ")\n",
        "print(f\"Datos cargados: {modelo.X.shape[0]} muestras\")\n",
        "print(f\"Dimensiones: entrada={modelo.input_dim}, salida={modelo.output_dim}\")\n",
        "\n",
        "# Ejecutamos la optimización con Optuna\n",
        "print(\"\\nOptimizando hiperparámetros con Optuna...\")\n",
        "modelo.optimizar(n_trials=10)\n",
        "\n",
        "# Entrenamos el mejor modelo encontrado\n",
        "print(\"\\nEntrenando el mejor modelo...\")\n",
        "modelo.entrenar_mejor_modelo()\n",
        "\n",
        "# Visualizaciones\n",
        "print(\"\\nGenerando gráficos...\")\n",
        "# Gráfico de pérdidas\n",
        "modelo.graficar_perdidas()\n",
        "\n",
        "# Evaluación y resumen\n",
        "print(\"\\nEvaluación del modelo:\")\n",
        "modelo.summary()\n",
        "\n",
        "# Guardar modelo y resultados\n",
        "nombre_carpeta = \"Comandos_LSTM\"\n",
        "modelo.guardar(nombre_carpeta)\n",
        "\n",
        "# Guardar métricas comparativas\n",
        "comparar_modelos_lstm(\n",
        "    nombre_modelo=\"Comandos_LSTM\",\n",
        "    ruta_datos=datos,\n",
        "    modelo=modelo\n",
        ")\n",
        "\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: 'UTF-8'\n",
        "\n",
        "!export LANG=C.UTF-8\n",
        "!export LC_ALL=C.UTF-8\n",
        "!export LC_CTYPE=C.UTF-8\n",
        "\n",
        "!cp -r {nombre_carpeta} /content/drive/MyDrive/Consultoria/Final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qh9ONZasLl72"
      },
      "outputs": [],
      "source": [
        "nombre_carpeta = \"Comandos_LSTM\"\n",
        "\n",
        "\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: 'UTF-8'\n",
        "\n",
        "!export LANG=C.UTF-8\n",
        "!export LC_ALL=C.UTF-8\n",
        "!export LC_CTYPE=C.UTF-8\n",
        "\n",
        "!cp -r {nombre_carpeta} /content/drive/MyDrive/Consultoria/Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7GKuuYEMdUy"
      },
      "outputs": [],
      "source": [
        "!cp -r {nombre_carpeta} /content/drive/MyDrive/Consultoria/Final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqFrvka0cjkf"
      },
      "source": [
        "## Datos Aleatorios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4mRPsB8ZZOu",
        "outputId": "de4e7262-8d5b-4280-fe79-d0e397b95458"
      },
      "outputs": [],
      "source": [
        "\n",
        "datos = r\"/content/drive/MyDrive/Consultoria/Final/Data/3ros/Aleatorio.csv\"\n",
        "\n",
        "modelo = LSTMInversaUR5(\n",
        "    ruta_datos=datos,\n",
        "    test_size=0.25,\n",
        "    random_state=42,\n",
        ")\n",
        "print(f\"Datos cargados: {modelo.X.shape[0]} muestras\")\n",
        "print(f\"Dimensiones: entrada={modelo.input_dim}, salida={modelo.output_dim}\")\n",
        "\n",
        "# Ejecutamos la optimización con Optuna\n",
        "print(\"\\nOptimizando hiperparámetros con Optuna...\")\n",
        "modelo.optimizar(n_trials=12)\n",
        "\n",
        "# Entrenamos el mejor modelo encontrado\n",
        "print(\"\\nEntrenando el mejor modelo...\")\n",
        "modelo.entrenar_mejor_modelo()\n",
        "\n",
        "# Visualizaciones\n",
        "print(\"\\nGenerando gráficos...\")\n",
        "# Gráfico de pérdidas\n",
        "modelo.graficar_perdidas()\n",
        "\n",
        "# Evaluación y resumen\n",
        "print(\"\\nEvaluación del modelo:\")\n",
        "modelo.summary()\n",
        "\n",
        "# Guardar modelo y resultados\n",
        "nombre_carpeta = \"Aleatorios\"\n",
        "modelo.guardar(nombre_carpeta)\n",
        "\n",
        "# Guardar métricas comparativas\n",
        "comparar_modelos_lstm(\n",
        "    nombre_modelo=\"Aleatorios\",\n",
        "    ruta_datos=datos,\n",
        "    modelo=modelo\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5qpTnPMOfai"
      },
      "outputs": [],
      "source": [
        "\n",
        "nombre_carpeta = \"Aleatorios_LSTM\"\n",
        "\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: 'UTF-8'\n",
        "\n",
        "!export LANG=C.UTF-8\n",
        "!export LC_ALL=C.UTF-8\n",
        "!export LC_CTYPE=C.UTF-8\n",
        "\n",
        "!cp -r {nombre_carpeta} /content/drive/MyDrive/Consultoria/Final\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF5v2WbDjFk6"
      },
      "source": [
        "## Trayectorias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Dc_sx-yojH7x",
        "outputId": "b2cf6f22-d8bd-42db-f331-f5b6b1af9cee"
      },
      "outputs": [],
      "source": [
        "\n",
        "datos = r\"/content/drive/MyDrive/Consultoria/Final/Data/Gen1/openaxes-example-robot-dataset/robot/Complete.csv\"\n",
        "\n",
        "modelo = LSTMInversaUR5(\n",
        "    ruta_datos=datos,\n",
        "    test_size=0.25,\n",
        "    random_state=42,\n",
        ")\n",
        "print(f\"Datos cargados: {modelo.X.shape[0]} muestras\")\n",
        "print(f\"Dimensiones: entrada={modelo.input_dim}, salida={modelo.output_dim}\")\n",
        "\n",
        "# Ejecutamos la optimización con Optuna\n",
        "print(\"\\nOptimizando hiperparámetros con Optuna...\")\n",
        "modelo.optimizar(n_trials=10)\n",
        "\n",
        "# Entrenamos el mejor modelo encontrado\n",
        "print(\"\\nEntrenando el mejor modelo...\")\n",
        "modelo.entrenar_mejor_modelo()\n",
        "\n",
        "# Visualizaciones\n",
        "print(\"\\nGenerando gráficos...\")\n",
        "# Gráfico de pérdidas\n",
        "modelo.graficar_perdidas()\n",
        "\n",
        "# Evaluación y resumen\n",
        "print(\"\\nEvaluación del modelo:\")\n",
        "modelo.summary()\n",
        "\n",
        "# Guardar modelo y resultados\n",
        "nombre_carpeta = \"Trayectorias_LSTM\"\n",
        "modelo.guardar(nombre_carpeta)\n",
        "\n",
        "# Guardar métricas comparativas\n",
        "comparar_modelos_lstm(\n",
        "    nombre_modelo=\"Trayectorias_LSTM\",\n",
        "    ruta_datos=datos,\n",
        "    modelo=modelo\n",
        ")\n",
        "nombre_carpeta = \"Trayectorias_LSTM\"\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: 'UTF-8'\n",
        "\n",
        "!export LANG=C.UTF-8\n",
        "!export LC_ALL=C.UTF-8\n",
        "!export LC_CTYPE=C.UTF-8\n",
        "\n",
        "!cp -r {nombre_carpeta} /content/drive/MyDrive/Consultoria/Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SEuwTbWVein"
      },
      "outputs": [],
      "source": [
        "nombre_carpeta = \"Trayectorias_LSTM\"\n",
        "!cp -r {nombre_carpeta} /content/drive/MyDrive/Consultoria/Final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVTSNM5rj-UH"
      },
      "source": [
        "## PesosVel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zWPiQjd4kFpL",
        "outputId": "e9fe3348-5302-48c9-96a2-357a3f67f7a3"
      },
      "outputs": [],
      "source": [
        "\n",
        "datos = r\"/content/drive/MyDrive/Consultoria/Final/Data/Gen2/NISTdata.csv\"\n",
        "\n",
        "modelo = LSTMInversaUR5(\n",
        "    ruta_datos=datos,\n",
        "    test_size=0.25,\n",
        "    random_state=42,\n",
        ")\n",
        "print(f\"Datos cargados: {modelo.X.shape[0]} muestras\")\n",
        "print(f\"Dimensiones: entrada={modelo.input_dim}, salida={modelo.output_dim}\")\n",
        "\n",
        "# Ejecutamos la optimización con Optuna\n",
        "print(\"\\nOptimizando hiperparámetros con Optuna...\")\n",
        "modelo.optimizar(n_trials=5)\n",
        "\n",
        "# Entrenamos el mejor modelo encontrado\n",
        "print(\"\\nEntrenando el mejor modelo...\")\n",
        "modelo.entrenar_mejor_modelo()\n",
        "\n",
        "# Visualizaciones\n",
        "print(\"\\nGenerando gráficos...\")\n",
        "# Gráfico de pérdidas\n",
        "modelo.graficar_perdidas()\n",
        "\n",
        "# Evaluación y resumen\n",
        "print(\"\\nEvaluación del modelo:\")\n",
        "modelo.summary()\n",
        "\n",
        "# Guardar modelo y resultados\n",
        "nombre_carpeta = \"PesosVel\"\n",
        "modelo.guardar(nombre_carpeta)\n",
        "\n",
        "# Guardar métricas comparativas\n",
        "comparar_modelos_lstm(\n",
        "    nombre_modelo=\"PesosVel_LSTM\",\n",
        "    ruta_datos=datos,\n",
        "    modelo=modelo\n",
        ")\n",
        "nombre_carpeta = \"PesosVel_LSTM\"\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: 'UTF-8'\n",
        "\n",
        "!export LANG=C.UTF-8\n",
        "!export LC_ALL=C.UTF-8\n",
        "!export LC_CTYPE=C.UTF-8\n",
        "\n",
        "!cp -r {nombre_carpeta} /content/drive/MyDrive/Consultoria/Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnDEpaXxbnRI"
      },
      "outputs": [],
      "source": [
        "!cp -r {nombre_carpeta} /content/drive/MyDrive/Consultoria/Final"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
